{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iI1RKNugRqsX",
    "outputId": "6851df40-4e6c-4834-9b20-4626677ee494"
   },
   "outputs": [],
   "source": [
    "## turn on the autocomplete if off by default\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5KhKjXY9DnX"
   },
   "source": [
    "## Below is a simple NN example in PyTorch to illustrate:\n",
    "1. Data Read (interactive)\n",
    "2. Normalize feature set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NkRi6Or6RhQk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "# Model Report Card\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1Pop5Em7qV-4"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBsyjESAFQHB",
    "outputId": "7c8ab5af-9884-4251-f7e6-4dde6dadd68f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# upload iris data interactively to google drive and access the data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# from google.colab import files\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# uploaded = files.upload()\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive\u001b[39m\u001b[38;5;124m'\u001b[39m, force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# upload iris data interactively to google drive and access the data\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "-nzkCDh2FQJn",
    "outputId": "0b6fd614-2728-42f7-cdb2-0acdbfd9cdb5"
   },
   "outputs": [],
   "source": [
    "# access data file\n",
    "# df = pd.read_csv(io.StringIO(uploaded['iris.csv'].decode('utf-8')))\n",
    "df = pd.read_csv(\"/content/gdrive/MyDrive/Solution Implementation Course/loans_2007.csv\")\n",
    "df.drop(df.columns[[0]], axis=1, inplace=True)# there is an unnamed column in the first col.\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "8WhcCL1SdrlK",
    "outputId": "9b8b4583-cdea-4f48-988c-99ed77e77e25"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFEX8qr3fF9O",
    "outputId": "85e3203f-1ca6-4b6d-fe91-89e985b10b5a"
   },
   "outputs": [],
   "source": [
    "df.verification_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sIfQvCjbZqD",
    "outputId": "e37ba936-4771-492f-b52b-af681b7a1767"
   },
   "outputs": [],
   "source": [
    "# what isthe structure of my dataset\n",
    "print(df.shape)\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "1vjcUzaERyzl",
    "outputId": "5e3d8a57-d6f7-4f35-fdc6-15cdde73cf49"
   },
   "outputs": [],
   "source": [
    "aggegate = df.loan_status.value_counts().to_frame('n')\n",
    "aggegate['percent'] = np.round(100*(aggegate['n']/(aggegate['n'].sum())),2)\n",
    "aggegate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nt21huxpP3SE"
   },
   "source": [
    "1. Remove all the columns that get added after loan issue\n",
    "> amount of loan <br/>\n",
    "> installment\n",
    "2. Any other variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msUtTxuLQE9g"
   },
   "outputs": [],
   "source": [
    "df.drop(['loan_amnt', 'installment', 'term'], axis=1, inplace=True)\n",
    "# df.drop(['installment', 'term'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpRcy9l3PjFT",
    "outputId": "a1a32e65-104e-4e95-fca4-eba47f386ba2"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bMRNwlzlb0nR",
    "outputId": "b7269c14-b743-4a57-ca5a-c531702f4fa1"
   },
   "outputs": [],
   "source": [
    "# Count total NaN at each column in a DataFrame\n",
    "print(\" \\nCount total NaN at each column in a DataFrame : \\n\\n\",\n",
    "      df.isnull().sum()/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18QazvlXd7fR"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['revol_util'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-pjOO-9d7hR"
   },
   "outputs": [],
   "source": [
    "# Make category of columns\n",
    "\n",
    "# Numerical variables ( can be continous (can take any numerical value) or discreet (can only take whole numbers as values) )\n",
    "# numerical_column = [ 'int_rate', 'emp_length', 'annual_inc', \\\n",
    "#                     'zip_code', 'dti', 'delinq_2yrs', 'fico_range_high', \\\n",
    "#                     'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal',\\\n",
    "#                     'revol_util', 'total_acc', 'last_fico_range_high']\n",
    "numerical_column = [ 'int_rate', 'emp_length', 'annual_inc', 'delinq_2yrs', 'fico_range_high','revol_bal', 'open_acc','loan_status']\n",
    "# Categorical - ( can be nominal (no order categories) or ordinal (ordered categories) )\n",
    "# categorical_column = ['home_ownership', 'verification_status', 'purpose']\n",
    "\n",
    "target_column = ['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyEOGxTngsE-",
    "outputId": "2b279eb6-a584-4994-8355-347a7c137c7a"
   },
   "outputs": [],
   "source": [
    "numerical_column[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6_Rnn8ygKXY",
    "outputId": "ec5a355d-3806-4a84-84e5-5139e2167a7b"
   },
   "outputs": [],
   "source": [
    "# Split into feature set \"X\" and target variable \"y\"\n",
    "y = df[target_column]\n",
    "df = df[numerical_column]\n",
    "X = df.drop(columns=target_column)\n",
    "print(f\"Shape of X: {X.shape}\\nShape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wkqRDMKXFQMa",
    "outputId": "8b95a1db-81e7-4dd6-f0c3-c610d8d854fa"
   },
   "outputs": [],
   "source": [
    "# Split data into train and test (Validation in our case)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=1, test_size=0.30)\n",
    "\n",
    "print(f\"Shape of Xtrain: {Xtrain.shape}\\n\\\n",
    "Shape of Xtest: {Xtest.shape}\\n\\\n",
    "Shape of ytrain: {ytrain.shape}\\n\\\n",
    "Shape of ytest: {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kdb_-femmKRG",
    "outputId": "f159c18c-3035-461f-b1ec-9d3aa4cd1b08"
   },
   "outputs": [],
   "source": [
    "# # Data transformation\n",
    "\n",
    "# # Scaling choosen as it bring data into range of 0 to 1 \n",
    "# ct = ColumnTransformer(transformers=[('standardscaler', StandardScaler(), numerical_column[:-1])])\n",
    "# # ct = ColumnTransformer(transformers=[('standardscaler', StandardScaler(), numerical_column),\n",
    "# #                                 ('onehotencoder', OneHotEncoder(drop=\"first\"), categorical_column)])\n",
    "# # Apply on Train features\n",
    "# ct.fit(Xtrain) # Learn the stats for this data set\n",
    "# Xtrain = ct.transform(Xtrain) # Apply Transformations\n",
    "\n",
    "# # Second way in one line\n",
    "# # ct.fit_transform(Xtrain)\n",
    "\n",
    "# # Apply on Test Features (Make sure you dont use Fit this time)\n",
    "# # You will apply the same stats for transfromation over test set which you have have learned over the training set.\n",
    "\n",
    "# Xtest = ct.transform(Xtest)\n",
    "\n",
    "# # Check\n",
    "# print(f\"Shape of Xtrain: {Xtrain.shape}\\n\\\n",
    "# Shape of Xtest: {Xtest.shape}\\n\\\n",
    "# Shape of ytrain: {ytrain.shape}\\n\\\n",
    "# Shape of ytest: {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vb8K4I5yVAq3"
   },
   "outputs": [],
   "source": [
    "# Here our X is in correct 2-d shape as a matrix\n",
    "# Convert y to 1-d array\n",
    "\n",
    "ytrain = ytrain.values.ravel()\n",
    "ytest = ytest.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-hf_4AlgBZ8",
    "outputId": "72c003d0-0e15-45b1-aa3d-7c199fddb771"
   },
   "outputs": [],
   "source": [
    "# Now the train a Logistics Regression Model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# model=RandomForestClassifier(class_weight='balanced')\n",
    "model = LogisticRegression(solver='newton-cg', class_weight='balanced')              # 1. instantiate model (Again you can sepcify the model specific Hyperparameters)\n",
    "\n",
    "model.fit(Xtrain, ytrain)                  # 2. fit model to data\n",
    "\n",
    "y_model = model.predict(Xtest)             # 3. predict on new data\n",
    "y_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6U-aSGhzprAb"
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame to store the results\n",
    "classification_results = pd.DataFrame(columns=['classifier_Name', 'Accuracy_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "DsTJZLxrgBds",
    "outputId": "6b798f3f-9023-4b15-a277-be1275c2d277"
   },
   "outputs": [],
   "source": [
    "# Make sure you pass the values in same order. First ytest (Orginal values) and then y_model (Model which will predict the y values)\n",
    "accuracy_score(ytest, y_model)\n",
    "classification_results = classification_results.append({'classifier_Name': 'Random forest', 'Accuracy_Score': accuracy_score(ytest, y_model)}, ignore_index=True)\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "GJe3klV5p5mZ",
    "outputId": "51487777-e4dc-428e-a529-8b3d9c705db5"
   },
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "# Format is -> confusion_matrix(Actual, Predicted)\n",
    "c_matrix = confusion_matrix(ytest, y_model)\n",
    "sns.heatmap(c_matrix.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.title('Naive Bayes Confusion Matrix')\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlZ-aWHLp5pP",
    "outputId": "43954bba-0db7-4aaf-9bdc-04b8eeb3bf7c"
   },
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6C28fRIap5sY"
   },
   "outputs": [],
   "source": [
    "# save model in a pickle format .pkl\n",
    "import pickle\n",
    "pickle_out = open(\"/content/gdrive/MyDrive/Solution Implementation Course/model.pkl\",\"wb\")\n",
    "pickle.dump(model, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DSSl_LoanModel",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
